INFO:openai:error_code=None error_message="This model's maximum context length is 4097 tokens, however you requested 4128 tokens (128 in your prompt; 4000 for the completion). Please reduce your prompt; or completion length." error_param=None error_type=invalid_request_error message='OpenAI API error received' stream_error=False
ERROR:root:This model's maximum context length is 4097 tokens, however you requested 4128 tokens (128 in your prompt; 4000 for the completion). Please reduce your prompt; or completion length.
INFO:openai:error_code=None error_message="This model's maximum context length is 4097 tokens, however you requested 4102 tokens (102 in your prompt; 4000 for the completion). Please reduce your prompt; or completion length." error_param=None error_type=invalid_request_error message='OpenAI API error received' stream_error=False
ERROR:root:This model's maximum context length is 4097 tokens, however you requested 4102 tokens (102 in your prompt; 4000 for the completion). Please reduce your prompt; or completion length.
INFO:openai:error_code=None error_message="This model's maximum context length is 4097 tokens, however you requested 4197 tokens (197 in your prompt; 4000 for the completion). Please reduce your prompt; or completion length." error_param=None error_type=invalid_request_error message='OpenAI API error received' stream_error=False
ERROR:root:This model's maximum context length is 4097 tokens, however you requested 4197 tokens (197 in your prompt; 4000 for the completion). Please reduce your prompt; or completion length.
INFO:openai:error_code=None error_message="This model's maximum context length is 4097 tokens, however you requested 4197 tokens (197 in your prompt; 4000 for the completion). Please reduce your prompt; or completion length." error_param=None error_type=invalid_request_error message='OpenAI API error received' stream_error=False
ERROR:root:This model's maximum context length is 4097 tokens, however you requested 4197 tokens (197 in your prompt; 4000 for the completion). Please reduce your prompt; or completion length.
INFO:openai:error_code=None error_message="This model's maximum context length is 4097 tokens, however you requested 4196 tokens (196 in your prompt; 4000 for the completion). Please reduce your prompt; or completion length." error_param=None error_type=invalid_request_error message='OpenAI API error received' stream_error=False
ERROR:root:This model's maximum context length is 4097 tokens, however you requested 4196 tokens (196 in your prompt; 4000 for the completion). Please reduce your prompt; or completion length.
